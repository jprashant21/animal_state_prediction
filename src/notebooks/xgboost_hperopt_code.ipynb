{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob as glob\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import ttest_ind,f_oneway\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "warnings.filterwarnings(action='once')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "#divide into train and test set\n",
    "TRAIN_START_DATE='2019-04-01 00:00:00'\n",
    "TRAIN_END_DATE='2019-08-31 00:00:00'\n",
    "TEST_START_DATE='2019-09-01 00:00:00'\n",
    "TEST_END_DATE='2019-11-14 00:00:00'\n",
    "ng_dist_shiftx_df=day_level_agg_df\n",
    "XGB_Train = ng_dist_shiftx_df[(ng_dist_shiftx_df.index >= TRAIN_START_DATE) &\n",
    "                                  (ng_dist_shiftx_df.index < TRAIN_END_DATE)]\n",
    "XGB_Test = ng_dist_shiftx_df[(ng_dist_shiftx_df.index >= TEST_START_DATE) &\n",
    "                                (ng_dist_shiftx_df.index < TEST_END_DATE)]\n",
    "\n",
    "XGB_Train.to_csv('TwoStage_PredictiveModel/Predictive_Model_XGB_Data/Classification_XGB_Train_Apr_Sep2019.csv')\n",
    "XGB_Test.to_csv('TwoStage_PredictiveModel/Predictive_Model_XGB_Data/Classification_XGB_Test_Apr_Sep2019.csv')\n",
    "print(\"Training data--Test data Date split\")\n",
    "print(XGB_Train.shape, XGB_Test.shape)  \n",
    "print(\"\\n\")\n",
    "# Create X, y datasets and train,Val datasets\n",
    "X = XGB_Train[XGB_Train.columns[2:-1]]\n",
    "#X = XGB_Train['Right1_min']\n",
    "y = XGB_Train['NG']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "# X_train = np.array(X_train).reshape(-1,1)\n",
    "# X_val = np.array(X_val).reshape(-1,1)\n",
    "# y_train = np.array(y_train).reshape(-1,1)\n",
    "# y_val = np.array(y_val).reshape(-1,1)\n",
    "#, X_val, y_train, y_val\n",
    "features = X_train.columns\n",
    "print(\"Training data--Validation data X-y split\")\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "print(features)\n",
    "print(\"training data NG sample percentage\",100*y_train.value_counts()[1]/sum(y_train.value_counts()))\n",
    "print(\"testing data NG sample percentage\",100*y_val.value_counts()[1]/sum(y_val.value_counts()))\n",
    "\n",
    "#Fitting XGB Classifier \n",
    "model = xgb.XGBClassifier(colsample_bytree=0.4,\n",
    "                 gamma=0,                 \n",
    "                 learning_rate=0.07,\n",
    "                 max_depth=3,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=1000,                                                                    \n",
    "                 reg_alpha=0.75,\n",
    "                 reg_lambda=0.45,\n",
    "                 subsample=0.6,\n",
    "                 seed=42)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(data=X_val)\n",
    "print (model)\n",
    "\n",
    "actual = y_val\n",
    "predicted = y_pred\n",
    "results = confusion_matrix(actual, predicted) \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(actual, predicted))\n",
    "print('Report : ')\n",
    "print(classification_report(actual, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = all_df[all_df.columns[:-1]]\n",
    "y = all_df[RESPONSE]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(1, 500)),\n",
    "    'max_depth': hp.choice('max_depth', range(3, 100)),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.01, 0.1, 0.01),\n",
    "    'silent': 1,\n",
    "    'objective': 'multi:softprob',\n",
    "    'nthread': -1, # set -1 to use all available scores\n",
    "    'gamma': hp.quniform('gamma', 0.1, 2, 0.01),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 0, 5, 0.5),\n",
    "    'subsample': hp.quniform('subsample', 0.1, 0.9, 0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.1, 0.9, 0.05),\n",
    "    'colsample_bylevel': hp.quniform('colsample_bylevel', 0.1, 0.9, 0.05),\n",
    "    #'colsample_bynode': hp.quniform('colsample_bynode', 0.1, 0.9, 0.05),\n",
    "    'reg_alpha' : hp.quniform('reg_alpha', 0, 1, 0.00001), # this parameter is for L1 regulation\n",
    "    'reg_lambda' : hp.quniform('reg_lambda', 0, 20, 0.1)\n",
    "}\n",
    "\n",
    "def objective(space):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "    model = xgb.XGBClassifier(\n",
    "            colsample_bylevel=space['colsample_bylevel'],\n",
    "            colsample_bytree=space['colsample_bytree'],\n",
    "            #colsample_bynode=space['colsample_bynode'],\n",
    "            gamma=space['gamma'],\n",
    "            learning_rate=space['learning_rate'],\n",
    "            max_depth=space['max_depth'],\n",
    "            min_child_weight=space['min_child_weight'],\n",
    "            n_estimators=space['n_estimators'],\n",
    "            nthread=space['nthread'],\n",
    "            objective=space['objective'],\n",
    "            random_state=0,\n",
    "            reg_alpha=space['reg_alpha'], \n",
    "            reg_lambda=space['reg_lambda'],\n",
    "            scale_pos_weight=1, \n",
    "            seed=None,\n",
    "            silent=space['silent'],\n",
    "            subsample=space['subsample'],\n",
    "            verbosity=1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return mean_squared_error(y_val,model.predict(X_val))\n",
    "\n",
    "\n",
    "\n",
    "best = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=100\n",
    ")\n",
    "print(best)\n",
    "\n",
    "best_model = xgb.XGBClassifier(\n",
    "            colsample_bylevel=best['colsample_bylevel'],\n",
    "            colsample_bytree=best['colsample_bytree'],\n",
    "            #colsample_bynode=best['colsample_bynode'],\n",
    "            gamma=best['gamma'],\n",
    "            learning_rate=best['learning_rate'],\n",
    "            max_depth=best['max_depth'],\n",
    "            min_child_weight=best['min_child_weight'],\n",
    "            n_estimators=best['n_estimators'],\n",
    "            random_state=0,\n",
    "            reg_alpha=best['reg_alpha'], \n",
    "            reg_lambda=best['reg_lambda'],\n",
    "            scale_pos_weight=1, \n",
    "            seed=None,\n",
    "            subsample=best['subsample'],\n",
    "            verbosity=1\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_val)\n",
    "actual = y_val\n",
    "predicted = y_pred\n",
    "results = confusion_matrix(actual, predicted) \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',f1_score(actual, predicted, average='micro'))\n",
    "print('Report : ')\n",
    "print(classification_report(actual, predicted))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
